{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of the training features dataset: (700, 2500)\n",
      "no. of emails in the training features = no. of emails in the training labels? True\n",
      "dimensions of the test features dataset: (260, 2500)\n",
      "no. of emails in the test features = no. of emails in the test labels? True\n",
      "classes in the training dataset and their counts: {0: 350, 1: 350}\n",
      "classes in the training dataset and their counts: {0: 130, 1: 130}\n"
     ]
    }
   ],
   "source": [
    "# reading the features of the training dataset\n",
    "x_train = pd.read_csv('example_data/train-features.txt', sep = \" \", header = None)\n",
    "x_train = x_train.to_numpy()\n",
    "# reading the label of the training dataset\n",
    "y_train = pd.read_csv('example_data/train-labels.txt', sep = '\\n', header = None)\n",
    "y_train = y_train[0].values.tolist()\n",
    "# reading the features of the test dataset\n",
    "x_test = pd.read_csv('example_data/test-features.txt', sep = \" \", header = None)\n",
    "x_test = x_test.to_numpy()\n",
    "# reading the labels of the test dataset\n",
    "y_test = pd.read_csv('example_data/test-labels.txt', sep = '\\n', header = None)\n",
    "y_test = y_test[0].values.tolist()\n",
    "\n",
    "# checking dimensions of the dataset\n",
    "print(\"dimensions of the training features dataset:\", x_train.shape)\n",
    "print(\"no. of emails in the training features = no. of emails in the training labels?\", len(y_train) == x_train.shape[0])\n",
    "print(\"dimensions of the test features dataset:\", x_test.shape)\n",
    "print(\"no. of emails in the test features = no. of emails in the test labels?\", len(y_test) == x_test.shape[0])\n",
    "\n",
    "# checking the number of classes in the dataset and whether they are imbalanced\n",
    "print(\"classes in the training dataset and their counts:\", dict(Counter(y_train)))\n",
    "print(\"classes in the training dataset and their counts:\", dict(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00501152 0.00393762 0.00191434 0.01760256 0.00091826]\n",
      "[0.01468118 0.01015245 0.01233177 0.00018072 0.0112049 ]\n"
     ]
    }
   ],
   "source": [
    "# learning the weights of the features\n",
    "def calc_cond_probs(x_train, dirichlet_alpha):\n",
    "    features_y0 = []\n",
    "    features_y1 = []\n",
    "    \n",
    "    # calculating the total number of words found in each class across all features\n",
    "    vocab_y0 = np.sum(x_train[:350,:])\n",
    "    vocab_y1 = np.sum(x_train[350:,:])\n",
    "\n",
    "    # calculating conditional probabilities for each feature for each class assuming a Dirichlet prior for smoothing\n",
    "    for i in range(x_train.shape[1]):\n",
    "            temp_y0_feat = (np.sum(x_train[:350, i]) + dirichlet_alpha)/(vocab_y0 + dirichlet_alpha*x_train.shape[1])\n",
    "            features_y0.append(temp_y0_feat)\n",
    "\n",
    "            temp_y1_feat = (np.sum(x_train[350:, i]) + dirichlet_alpha)/(vocab_y1 + dirichlet_alpha*x_train.shape[1])\n",
    "            features_y1.append(temp_y1_feat)\n",
    "\n",
    "    return np.array(features_y0), np.array(features_y1)\n",
    "\n",
    "# the the hyperparameter dirichlet_alpha was set to be 1\n",
    "# dirichlet_alpha is not yet optimized\n",
    "w_y0, w_y1 = calc_cond_probs(x_train, dirichlet_alpha=1)\n",
    "\n",
    "print(\"feature weights for class 0:\", w_y0[:5])\n",
    "print(\"feature weights for class 1:\", w_y1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-145.7770372776866, -137.42774744458674, -975.8265938223943, -435.5389319660713, -271.8035324777869]\n",
      "[-168.1442994983499, -183.7289678737881, -1163.7451814682588, -521.9402014440582, -314.335999938414]\n"
     ]
    }
   ],
   "source": [
    "def calc_log_likelihood(f_y0, f_y1, x):\n",
    "\n",
    "    log_likelihood_y0 = []\n",
    "    log_likelihood_y1 = []\n",
    "\n",
    "    # calculating log likelihoods using weights of features for the dataset of interest \n",
    "    for i in range(x.shape[0]):\n",
    "        log_likelihood_y0.append(sum(np.log(f_y0)*x[i, :]))\n",
    "        log_likelihood_y1.append(sum(np.log(f_y1)*x[i, :]))\n",
    "\n",
    "    return log_likelihood_y0, log_likelihood_y1\n",
    "\n",
    "# calculating log likelikhoods for the training dataset\n",
    "log_w_y0, log_w_y1 = calc_log_likelihood(w_y0, w_y1, x_train)\n",
    "\n",
    "print(\"log likelihoods of observations for class 0:\", log_w_y0[:5])\n",
    "print(\"log likelihoods of observations for class 1:\", log_w_y1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-146.47018446 -138.12089463 -976.519741   -436.23207915 -272.49667966]\n",
      "[ -168.83744668  -184.42211505 -1164.43832865  -522.63334862\n",
      "  -315.02914712]\n"
     ]
    }
   ],
   "source": [
    "def calc_posterior(logLH_y0, logLH_y1, y):\n",
    "    # calculating priors for classes\n",
    "    log_prior_y0 = np.log(y.count(0)/len(y))\n",
    "    log_prior_y1 = np.log(y.count(1)/len(y))\n",
    "\n",
    "    # calculating posteriors for classes for each observation\n",
    "    posterior_y0 = logLH_y0 + log_prior_y0\n",
    "    posterior_y1 = logLH_y1 + log_prior_y1\n",
    "\n",
    "    return posterior_y0, posterior_y1\n",
    "\n",
    "# calculating posteriors for the training dataset\n",
    "posterior_y0, posterior_y1 = calc_posterior(log_w_y0, log_w_y1, y_train)\n",
    "\n",
    "print(\"posterior probabilities of observation for class 0:\", posterior_y0[:5])\n",
    "print(\"posterior probabilities of observation for class 1:\", posterior_y1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 98.71%\n",
      "confusion matrix:\n",
      "[[349   1]\n",
      " [  8 342]]\n"
     ]
    }
   ],
   "source": [
    "def classify(p_y0, p_y1, y):\n",
    "    \n",
    "    # predicted class labels for the dataset of interest\n",
    "    class_pred = [0 if p_y0[i] > p_y1[i] or p_y0[i] == p_y1[i] else 1 for i in range(len(y))]\n",
    "\n",
    "    # calculating true positives, false positives, true negatives, and false negatives\n",
    "    true_pos = len([i for i in range(len(y)) if y[i] == 0 and class_pred[i] == 0])\n",
    "    true_neg = len([i for i in range(len(y)) if y[i] == 1 and class_pred[i] == 1])\n",
    "    false_pos = len([i for i in range(len(y)) if y[i] == 0 and class_pred[i] == 1])\n",
    "    false_neg = len([i for i in range(len(y)) if y[i] == 1 and class_pred[i] == 0])\n",
    "    \n",
    "    # constructing a confusion matrix\n",
    "    confusion_matrix = np.array([[true_pos, false_pos],[false_neg, true_neg]])\n",
    "    # calculating accuracy of the model\n",
    "    accuracy = (true_pos + true_neg)/len(y)\n",
    "\n",
    "    return class_pred, accuracy, confusion_matrix\n",
    "\n",
    "# predicting the training dataset labels and calculating training accuracy\n",
    "y_predicted, model_accuracy, model_confusion = classify(posterior_y0, posterior_y1, y_train)\n",
    "\n",
    "print(\"Model accuracy is {:0.2f}%\".format(model_accuracy*100))\n",
    "print(\"Training confusion matrix:\")\n",
    "print(model_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification accuracy: 98.71%\n",
      "Test classification accuracy: 97.31%\n",
      "Test confusion matrix:\n",
      "[[127   3]\n",
      " [  4 126]]\n"
     ]
    }
   ],
   "source": [
    "# combining all of the above functions to train and test the multinomial naive bayes' model\n",
    "def NB_classification(x_train, x_test, y_train, y_test, dirichlet_alpha):\n",
    "    \n",
    "    # training the model\n",
    "    f_y0, f_y1 = calc_cond_probs(x_train, dirichlet_alpha)\n",
    "\n",
    "    # class prediction on training dataset\n",
    "    logLH_train_y0, logLH_train_y1 = calc_log_likelihood(f_y0, f_y1, x_train)\n",
    "    posterior_train_y0, posterior_train_y1 = calc_posterior(logLH_train_y0, logLH_train_y1, y_train)\n",
    "    train_class_pred, training_accuracy, train_confusion = classify(posterior_train_y0, posterior_train_y1, y_train)\n",
    "\n",
    "    # class prediction on test dataset\n",
    "    logLH_test_y0, logLH_test_y1 = calc_log_likelihood(f_y0, f_y1, x_test)\n",
    "    posterior_test_y0, posterior_test_y1 = calc_posterior(logLH_test_y0, logLH_test_y1, y_train)\n",
    "    test_class_pred, test_accuracy, test_confusion = classify(posterior_test_y0, posterior_test_y1, y_test)\n",
    "    \n",
    "    # printing out prediction accuracy on training and test datasets\n",
    "    print(\"Training classification accuracy: {:0.2f}%\".format(training_accuracy*100))\n",
    "    print(\"Test classification accuracy: {:0.2f}%\".format(test_accuracy*100))\n",
    "\n",
    "    return test_class_pred, test_confusion\n",
    "\n",
    "y_test_pred, test_confusion_matrix = NB_classification(x_train, x_test, y_train, y_test, dirichlet_alpha=1)\n",
    "print(\"Test confusion matrix:\")\n",
    "print(test_confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d35480b5c1d294382b0e0921d54eccdfa53dc59be22530d71db640e0bbad820"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
